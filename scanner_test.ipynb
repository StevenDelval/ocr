{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def biggest_contour(contours):\n",
    "#     biggest = np.array([])\n",
    "#     max_area = 0\n",
    "#     for i in contours:\n",
    "#         area = cv2.contourArea(i)\n",
    "#         if area > 1000:\n",
    "#             peri = cv2.arcLength(i, True)\n",
    "#             approx = cv2.approxPolyDP(i, 0.015 * peri, True)\n",
    "#             if area > max_area and len(approx) == 4:\n",
    "#                 biggest = approx\n",
    "#                 max_area = area\n",
    "#     return biggest\n",
    "\n",
    "\n",
    "# # Open a connection to the webcam (use 0 for the default camera)\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     # Capture frame-by-frame\n",
    "#     ret, frame = cap.read()\n",
    "#     img_original = frame.copy()\n",
    "    \n",
    "#     # Break the loop if there's an issue capturing the frame\n",
    "#     if not ret:\n",
    "#         print(\"Error: Failed to capture frame.\")\n",
    "#         break\n",
    "\n",
    "#     # Grayscale\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Find Canny edges\n",
    "#     edged = cv2.Canny(gray, 30, 200)\n",
    "\n",
    "#     # Finding Contours\n",
    "#     contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#     # Print the number of contours found\n",
    "#     print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "#     biggest = biggest_contour(contours)\n",
    "#     print(\"Number of Biggest Contours found = \" + str(len(biggest)))\n",
    "#     if len(biggest !=0):\n",
    "\n",
    "#         cv2.drawContours(frame, [biggest], -1, (0, 255, 0), 3)\n",
    "#         # Pixel values in the original image\n",
    "#         points = biggest.reshape(4, 2)\n",
    "#         input_points = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "#         points_sum = points.sum(axis=1)\n",
    "#         input_points[0] = points[np.argmin(points_sum)]\n",
    "#         input_points[3] = points[np.argmax(points_sum)]\n",
    "\n",
    "#         points_diff = np.diff(points, axis=1)\n",
    "#         input_points[1] = points[np.argmin(points_diff)]\n",
    "#         input_points[2] = points[np.argmax(points_diff)]\n",
    "\n",
    "#         (top_left, top_right, bottom_right, bottom_left) = input_points\n",
    "#         bottom_width = np.sqrt(((bottom_right[0] - bottom_left[0]) ** 2) + ((bottom_right[1] - bottom_left[1]) ** 2))\n",
    "#         top_width = np.sqrt(((top_right[0] - top_left[0]) ** 2) + ((top_right[1] - top_left[1]) ** 2))\n",
    "#         right_height = np.sqrt(((top_right[0] - bottom_right[0]) ** 2) + ((top_right[1] - bottom_right[1]) ** 2))\n",
    "#         left_height = np.sqrt(((top_left[0] - bottom_left[0]) ** 2) + ((top_left[1] - bottom_left[1]) ** 2))\n",
    "\n",
    "#         # Output image size\n",
    "#         max_width = max(int(bottom_width), int(top_width))\n",
    "#         # max_height = max(int(right_height), int(left_height))\n",
    "#         max_height = int(max_width * 1.414)  # for A4\n",
    "\n",
    "#         # Desired points values in the output image\n",
    "#         converted_points = np.float32([[0, 0], [max_width, 0], [0, max_height], [max_width, max_height]])\n",
    "\n",
    "#         # Perspective transformation\n",
    "#         matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "#         img_output = cv2.warpPerspective(img_original, matrix, (max_width, max_height))\n",
    "\n",
    "#         # Resize the image to the fixed size\n",
    "#         img_output = cv2.resize(img_output, (460, 800))\n",
    "\n",
    "#         # Image shape modification for hstack\n",
    "#         gray = np.stack((gray,) * 3, axis=-1)\n",
    "#         edged = np.stack((edged,) * 3, axis=-1)\n",
    "\n",
    "#         img_hor = np.hstack((img_original, gray, edged))\n",
    "#         cv2.imshow(\"Contour detection\", img_hor)\n",
    "#         cv2.imshow(\"Warped perspective\", img_output)\n",
    "\n",
    "\n",
    "#     # Display the frame with contours\n",
    "#     cv2.imshow('Contours', frame)\n",
    "\n",
    "#     # Break the loop if 'q' key is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the webcam and close all windows\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   1   -1   -1   -1]\n",
      "  [   2    0   -1   -1]\n",
      "  [1748    1    3   -1]\n",
      "  ...\n",
      "  [  -1 1746   -1    2]\n",
      "  [1749    2   -1   -1]\n",
      "  [  -1 1748   -1   -1]]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import platform\n",
    "if platform.system() == \"Windows\":\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\B92383\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe'\n",
    "custom_config = r'--oem 2 --psm 12 -l fra+eng'\n",
    "\n",
    "def image2text(image):\n",
    "    text = ''\n",
    "    \n",
    "\n",
    "    text = pytesseract.image_to_string(image, config=custom_config)\n",
    "\n",
    "    if len(text)!=0:\n",
    "        return text\n",
    "    else:\n",
    "        return \"no text detected\"\n",
    "\n",
    "def biggest_contour(contours):\n",
    "    biggest = np.array([])\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i)\n",
    "        if area > 1000:\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.015 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "    return biggest\n",
    "\n",
    "\n",
    "img = cv2.imread('carte-grise-specimen_rot.jpg')\n",
    "img = np.array(Image.fromarray(img.copy()).rotate(65,resample=Image.BICUBIC, expand=True))\n",
    "img_original = img.copy()\n",
    "\n",
    "# Image modification\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bilateralFilter(gray, 20, 30, 30)\n",
    "edged = cv2.Canny(gray, 10, 20)\n",
    "\n",
    "# Contour detection\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(hierarchy)\n",
    "\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "biggest = biggest_contour(contours)\n",
    "\n",
    "cv2.drawContours(img, [biggest], -1, (0, 255, 0), 3)\n",
    "\n",
    "# Pixel values in the original image\n",
    "points = biggest.reshape(4, 2)\n",
    "input_points = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "points_sum = points.sum(axis=1)\n",
    "input_points[0] = points[np.argmin(points_sum)]\n",
    "input_points[3] = points[np.argmax(points_sum)]\n",
    "\n",
    "points_diff = np.diff(points, axis=1)\n",
    "input_points[1] = points[np.argmin(points_diff)]\n",
    "input_points[2] = points[np.argmax(points_diff)]\n",
    "\n",
    "(top_left, top_right, bottom_right, bottom_left) = input_points\n",
    "bottom_width = np.sqrt(((bottom_right[0] - bottom_left[0]) ** 2) + ((bottom_right[1] - bottom_left[1]) ** 2))\n",
    "top_width = np.sqrt(((top_right[0] - top_left[0]) ** 2) + ((top_right[1] - top_left[1]) ** 2))\n",
    "right_height = np.sqrt(((top_right[0] - bottom_right[0]) ** 2) + ((top_right[1] - bottom_right[1]) ** 2))\n",
    "left_height = np.sqrt(((top_left[0] - bottom_left[0]) ** 2) + ((top_left[1] - bottom_left[1]) ** 2))\n",
    "\n",
    "# Output image size\n",
    "max_width = max(int(bottom_width), int(top_width))\n",
    "# max_height = max(int(right_height), int(left_height))\n",
    "max_height = int(max_width * 2.035)  # for A4\n",
    "\n",
    "converted_points = np.float32([[0, 0], [max_width, 0], [0, max_height], [max_width, max_height]])\n",
    "\n",
    "# Perspective transformation\n",
    "matrix = cv2.getPerspectiveTransform(input_points, converted_points)\n",
    "img_output = cv2.warpPerspective(img_original, matrix, (max_width, max_height))\n",
    "\n",
    "# for rot in range(4):\n",
    "            \n",
    "#             img_output_to_test_text = img_output[0:30, :]\n",
    "#             cv2.imshow(\"Warped perspective\", img_output_to_test_text)\n",
    "#             cv2.waitKey(0)\n",
    "            \n",
    "#             word_found_to_test = image2text(img_output_to_test_text)\n",
    "            \n",
    "#             print(word_found_to_test)\n",
    "#             if \"immatriculation\" in word_found_to_test.lower():\n",
    "#                 print(\"OK\")\n",
    "#                 break\n",
    "#             else:\n",
    "#                 img_output = np.array(Image.fromarray(img_output.copy()).rotate(90,resample=Image.BICUBIC, expand=True))\n",
    " # Resize the image to the fixed size\n",
    "# img_output = cv2.resize(img_output, (460, 800),interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# Image shape modification for hstack\n",
    "gray = np.stack((gray,) * 3, axis=-1)\n",
    "edged = np.stack((edged,) * 3, axis=-1)\n",
    "\n",
    "img_hor = np.hstack((img_original, gray, edged, img))\n",
    "cv2.imshow(\"Contour detection\", img_hor)\n",
    "cv2.imshow(\"Warped perspective\", img_output)\n",
    "\n",
    "# cv2.imwrite('output/document.jpg', img_output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    '''Rearrange coordinates to order:\n",
    "       top-left, top-right, bottom-right, bottom-left'''\n",
    "    rect = np.zeros((4, 2), dtype='float32')\n",
    "    pts = np.array(pts)\n",
    "    s = pts.sum(axis=1)\n",
    "    # Top-left point will have the smallest sum.\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    # Bottom-right point will have the largest sum.\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    # Top-right point will have the smallest difference.\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    # Bottom-left will have the largest difference.\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect.astype('int').tolist()\n",
    "\n",
    "\n",
    "def find_dest(pts):\n",
    "    (tl, tr, br, bl) = pts\n",
    "    # Finding the maximum width.\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # Finding the maximum height.\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # Final destination co-ordinates.\n",
    "    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]\n",
    "\n",
    "    return order_points(destination_corners)\n",
    "\n",
    "\n",
    "\n",
    "def scan(img):\n",
    "    # Resize image to workable size\n",
    "    # dim_limit = 1080\n",
    "    # max_dim = max(img.shape)\n",
    "    # if max_dim > dim_limit:\n",
    "    #     resize_scale = dim_limit / max_dim\n",
    "    #     img = cv2.resize(img, None, fx=resize_scale, fy=resize_scale)\n",
    "    \n",
    "    # img = cv2.resize(img, (1400, 1800))\n",
    "    # Create a copy of resized original image for later use\n",
    "\n",
    "    orig_img = img.copy()\n",
    "    # Repeated Closing operation to remove text from the document.\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    # GrabCut\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    rect = (20, 20, img.shape[1] - 20, img.shape[0] - 20)\n",
    "    cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "    img = img * mask2[:, :, np.newaxis]\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "    # Edge Detection.\n",
    "    canny = cv2.Canny(gray, 0, 200)\n",
    "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
    "\n",
    "    # Finding contours for the detected edges.\n",
    "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    # Keeping only the largest detected contour.\n",
    "    page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "    # Detecting Edges through Contour approximation.\n",
    "    # Loop over the contours.\n",
    "    if len(page) == 0:\n",
    "        return orig_img\n",
    "    for c in page:\n",
    "        # Approximate the contour.\n",
    "        epsilon = 0.02 * cv2.arcLength(c, True)\n",
    "        corners = cv2.approxPolyDP(c, epsilon, True)\n",
    "        # If our approximated contour has four points.\n",
    "        if len(corners) == 4:\n",
    "            break\n",
    "    # Sorting the corners and converting them to desired shape.\n",
    "    corners = sorted(np.concatenate(corners).tolist())\n",
    "    # For 4 corner points being detected.\n",
    "    corners = order_points(corners)\n",
    "\n",
    "    destination_corners = find_dest(corners)\n",
    "\n",
    "    # Getting the homography.\n",
    "    M = cv2.getPerspectiveTransform(np.float32(corners), np.float32(destination_corners))\n",
    "    # Perspective transform using homography.\n",
    "    final = cv2.warpPerspective(orig_img, M, (destination_corners[2][0], destination_corners[2][1]),\n",
    "                                flags=cv2.INTER_LINEAR)\n",
    "    final = cv2.resize(final, (1200, 1600))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = cv2.imread('ci.jpg')\n",
    "\n",
    "img_original = img.copy()\n",
    "\n",
    "img_output = scan(img)\n",
    "img_output = cv2.resize(img_output, (600,800))\n",
    "\n",
    "cv2.imshow(\"Contour detection\", img_original)\n",
    "cv2.imshow(\"Warped perspective\", img_output)\n",
    "\n",
    "cv2.imwrite('output/document.jpg', img_output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
