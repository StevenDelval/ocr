{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import platform\n",
    "if platform.system() == \"Windows\":\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\B92383\\AppData\\Local\\Programs\\Tesseract-OCR\\tesseract.exe'\n",
    "custom_config = r'--oem 2 --psm 12 -l fra+eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 1\n",
    "### Standariser l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image):\n",
    "    \"\"\"\n",
    "    Resize the input image to a fixed size of (1946, 1080).\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (OpenCV format)\n",
    "\n",
    "    Returns:\n",
    "    - Resized image\n",
    "    \"\"\"\n",
    "    # Resize the image to the fixed size\n",
    "    resized_image = cv2.resize(image, (460, 800))\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def biggestRectangle(contours):\n",
    "    max_area = 0\n",
    "    indexReturn = -1\n",
    "    for index in range(len(contours)):\n",
    "        i = contours[index]\n",
    "        area = cv2.contourArea(i)\n",
    "        if area > 100:\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.1 * peri, True)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                indexReturn = index\n",
    "    return indexReturn\n",
    "\n",
    "\n",
    "def image_brightness(img):\n",
    "    \"\"\"\n",
    "    Process the input image by converting color space, applying gamma correction,\n",
    "    and applying binary thresholding.\n",
    "\n",
    "    Parameters:\n",
    "    - img: Input image (OpenCV format)\n",
    "\n",
    "    Returns:\n",
    "    - Processed image\n",
    "    \"\"\"\n",
    "    # Convert color space from BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply gamma correction\n",
    "    invGamma = 1.0 / 0.3\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    gray = cv2.LUT(gray, table)\n",
    "\n",
    "    # Apply binary thresholding\n",
    "    _, thresh1 = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return thresh1\n",
    "\n",
    "\n",
    "def process_image(img):\n",
    "    \n",
    "    thresh1 = image_brightness(img)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "    indexReturn = biggestRectangle(contours)\n",
    "    hull = cv2.convexHull(contours[indexReturn])\n",
    "\n",
    "    mask = np.zeros_like(img)\n",
    "    cv2.drawContours(mask, contours, indexReturn, 255, -1)\n",
    "    out = np.zeros_like(img)\n",
    "    out[mask == 255] = img[mask == 255]\n",
    "    \n",
    "\n",
    "    (y, x, _) = np.where(mask == 255)\n",
    "    (topy, topx) = (np.min(y), np.min(x))\n",
    "    (bottomy, bottomx) = (np.max(y), np.max(x))\n",
    "    out = img[topy:bottomy + 1, topx:bottomx + 1, :]\n",
    "    out = resize_image(out)\n",
    "    \n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to trim and save an image\n",
    "def trim_and_save(region_key, region_points, image):\n",
    "    x, y, w, h = cv2.boundingRect(np.array(region_points))\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "    cv2.imwrite(f\"./img/{region_key}_cropped.jpg\", cropped_image)\n",
    "\n",
    "\n",
    "\n",
    "def image2text(cropped_image_path):\n",
    "    text = ''\n",
    "    \n",
    "    cropped_image = cv2.imread(cropped_image_path)\n",
    "\n",
    "    text = pytesseract.image_to_string(cropped_image, config=custom_config)\n",
    "\n",
    "    if len(text)!=0:\n",
    "        return text\n",
    "    else:\n",
    "        print(\"no text detected\")\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2656, 1472, 3)\n",
      "(800, 460, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load your image\n",
    "image_path = \"/home/apprenant/Bureau/ocr/carte-grise-specimen.jpg\"\n",
    "# image = Image.open(image)\n",
    "frame = cv2.imread(image_path)\n",
    "print(frame.shape)\n",
    "# print(frame)\n",
    "frame = process_image(frame)\n",
    "\n",
    "print(frame.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 2 :\n",
    "### Trouver les points de chaque element dans la photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def mouse_drawing(event, x, y, flags, params):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Left click\")\n",
    "        circles.append((x, y))\n",
    "\n",
    "circles = []\n",
    "\n",
    "# Load your image\n",
    "# image_path = \"img\\carte-grise-specimen.jpg\"\n",
    "# frame = cv2.imread(image_path)\n",
    "\n",
    "cv2.namedWindow(\"Frame\")\n",
    "if len(circles) < 4:\n",
    "    cv2.setMouseCallback(\"Frame\", mouse_drawing)\n",
    "\n",
    "while True:\n",
    "    for center_position in circles:\n",
    "        cv2.circle(frame, center_position, 2, (0, 0, 255), -1)\n",
    "    \n",
    "    points = np.array(circles)\n",
    "    if len(circles) >= 4:\n",
    "        cv2.polylines(frame, np.int32([points]), 1, (255, 255, 255))\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "    elif key == ord(\"d\"):\n",
    "        circles = []\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(circles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113, 0)\n"
     ]
    }
   ],
   "source": [
    "regions_dict = {\n",
    "    'points_N_immatriculation':[(31, 35), (31, 46), (100, 49), (101, 35)],\n",
    "    'points_titre_document': [(113, 0), (114, 15), (339, 15), (336, 0)],\n",
    "    'points_d_2': [(38, 242), (38, 262), (359, 262), (359, 242)],\n",
    "    'points_E': [(288, 276), (289, 293), (412, 295), (412, 275)],\n",
    "    'points_Date_de_1er_immarticulation': [(145, 37), (146, 50), (228, 51), (226, 36)]\n",
    "}\n",
    "\n",
    "# Accessing values for a specific key\n",
    "print(regions_dict['points_titre_document'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 3\n",
    "### couper les elements et les save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Iterate through regions and trim/save images\n",
    "for region_key, region_points in regions_dict.items():\n",
    "    trim_and_save(region_key, region_points, frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 4\n",
    "### Passer le PCR pour chaque image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    for region_key, value in regions_dict.items():\n",
    "        cv2.rectangle(frame, value[0], value[2], (0,0,255),2,2)\n",
    "         # Load the saved cropped image\n",
    "        cropped_image_path = f\"{region_key}_cropped.jpg\"\n",
    "        # cropped_image = cv2.imread(cropped_image_path)\n",
    "        word_found = image2text(cropped_image_path)\n",
    "        # print(f\"{region_key} : {word_found}\")\n",
    "        cv2.putText(frame, str(word_found), value[0],1,1,(0,0,255),1)\n",
    "\n",
    "    \n",
    " \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_var = {}\n",
    "for region_key, value in regions_dict.items():\n",
    "        cv2.rectangle(frame, value[0], value[2], (0,0,255),2,2)\n",
    "         # Load the saved cropped image\n",
    "        cropped_image_path = f\"./img/{region_key}_cropped.jpg\"\n",
    "        # cropped_image = cv2.imread(cropped_image_path)\n",
    "        word_found = image2text(cropped_image_path)\n",
    "        liste_var[region_key]=word_found.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'points_N_immatriculation': 'AB-123-CD',\n",
       " 'points_titre_document': \"CERTIFICAT D'IMNATAICULATION\",\n",
       " 'points_d_2': 'VERSION',\n",
       " 'points_E': 'WFSIV2009ASIV2009',\n",
       " 'points_Date_de_1er_immarticulation': '05/01/1996'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "from io import BytesIO\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import A4\n",
    "\n",
    "buffer = BytesIO()\n",
    "\n",
    "# create a new PDF with Reportlab\n",
    "p = canvas.Canvas(buffer, pagesize=A4)\n",
    "dict_pos = {\n",
    "    'points_N_immatriculation':[50, 705],\n",
    "    'points_d_2': [50, 630],\n",
    "    'points_E': [50, 610],\n",
    "}\n",
    "for region_key in dict_pos.keys():\n",
    "    p.drawString(*dict_pos[region_key], liste_var[region_key])\n",
    "p.showPage()\n",
    "p.save()\n",
    "\n",
    "#move to the beginning of the StringIO buffer\n",
    "buffer.seek(0)\n",
    "newPdf = PdfReader(buffer)\n",
    "\n",
    "# #######DEBUG NEW PDF created#############\n",
    "# pdf1 = buffer.getvalue()\n",
    "# open('pdf1.pdf', 'wb').write(pdf1)\n",
    "#########################################\n",
    "# read your existing PDF\n",
    "existingPdf = PdfReader(open('cerfa_13750-07.pdf', 'rb'))\n",
    "output = PdfWriter()\n",
    "# add the \"watermark\" (which is the new pdf) on the existing page\n",
    "page = existingPdf.pages[0]\n",
    "page.merge_page(newPdf.pages[0])\n",
    "output.add_page(page)\n",
    "# finally, write \"output\" to a real file\n",
    "outputStream = open('output.pdf', 'wb')\n",
    "output.write(outputStream)\n",
    "outputStream.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
